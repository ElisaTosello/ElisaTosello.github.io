<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<!--
Awesome Template
http://www.templatemo.com/preview/templatemo_450_awesome
-->
<title>Elisa Tosello, PhD</title>
<meta name="keywords" content="">
<meta name="description" content="">
<meta http-equiv="X-UA-Compatible" content="IE=Edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

<link rel="stylesheet" href="css/animate.min.css">
<link rel="stylesheet" href="css/bootstrap.min.css">
<link rel="stylesheet" href="css/font-awesome.min.css">
<link href='http://fonts.googleapis.com/css?family=Open+Sans:400,300,600,700' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="css/templatemo-style.css">
<script src="js/jquery.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/jquery.singlePageNav.min.js"></script>
<script src="js/typed.js"></script>
<script src="js/wow.min.js"></script>
<script src="js/custom.js"></script>
</head>
<body>

</head>
<body id="top">

<!-- start preloader -->
<div class="preloader">
	<div class="sk-spinner sk-spinner-wave">
		<div class="sk-rect1"></div>
		<div class="sk-rect2"></div>
		<div class="sk-rect3"></div>
		<div class="sk-rect4"></div>
		<div class="sk-rect5"></div>
	</div>
</div>
<!-- end preloader -->

<!-- start header -->
<header>
	<div class="container">
		<div class="row">
			<div class="col-md-3 col-sm-4 col-xs-12">
				<p><i class="fa fa-envelope-o"></i><span> Email</span><a href="mailto:etosello@fbk.eu" style="color:#09A9C8;">etosello@fbk.eu</a> </p>
			</div>
		</div>
	</div>
</header>
<!-- end header -->

<!-- start navigation -->
<nav class="navbar navbar-default templatemo-nav" role="navigation">
	<div class="container">
		<div class="navbar-header">
			<button class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
				<span class="icon icon-bar"></span>
				<span class="icon icon-bar"></span>
				<span class="icon icon-bar"></span>
			</button>
			<a href="#" class="navbar-brand">VITAE</a>
		</div>
		<div class="collapse navbar-collapse">
			<ul class="nav navbar-nav navbar-right">
				<li><a href="#top">Home</a></li>
				<li><a href="#about">Short Bio</a></li>
				<li><a href="#photo">Resumé</a></li>
				<li><a href="#research">Research</a></li>
				<li><a href="#code">Code</a></li>
				<li><a href="#teaching">Teaching</a></li>
				<li><a href="#publications">Publications</a></li>
			</ul>
		</div>
	</div>
</nav>
<!-- end navigation -->

<!-- start home -->
<section id="home">
	<div class="container">
		<div class="row">
			<div class="col-md-offset-2 col-md-8">
				<h1>I'm <b style="color:#09A9C8;">Elisa Tosello</b></h1>
			</br>
			<div class="element">
				<div><b>Robotics, PhD </b></div>
				<div>Embedded Systems - Fondazione Bruno Kessler </div>
				<br><br><br>
				<!--div class="wow fadeIn" data-wow-offset="50" data-wow-delay="0.3s"><i>"The joy of discovery is certainty the liveliest that the mind of man can ever feel"</i></div>
				<div class="wow fadeIn" data-wow-offset="50" data-wow-delay="0.4s"> C. Bernard</div-->
				<div>RESARCH INTERESTS:</div>
				<div><b>Artificial Intelligent Planning and Reasoning for Digital Industry and Robotics. </b></div>
			</div>
		</div>
	</div>
</div>
</section>
<!-- end home -->

<!-- start about -->
<section id="about">
<div class="container">
	<div class="row">
		<div class="col-md-12">
			<h2>SHOT BIO</h2>
			<h2 style="line-height:15px;"><small>
				I'm Post-Doc Researcher at the Embedded Systems unit in Fondazione Bruno Kessler (Trento, Italy). Until 2021, I was a Senior Post-Doc in the Intelligent Autonomous System Laboratory (IAS-Lab) of the Department of Information Engineering at the University of Padova (Italy), where I was also a Contract Professor of Autonomous Robotics from 2017 to 2020. I received my Ph.D. (2016), M.Sc. (2012), and B.Sc. (2009) in Computer Engineering at the University of Padova. My research focuses on Artificial Intelligent Planning and Reasoning for Digital Industry and Robotics. Specifically, I was responsible for the task scheduling and motion planning activity of CURAMI, a project supported by Fondazione Cariverona and the University of Padova on human-robot collaboration for intelligent assembly tasks. In this context, I applied Deep Reinforcement Learning techniques to solve Task and Motion Planning problems for Cognitive Robots. Such an interest came about after a period of Visiting Scholar at Rice University in Houston (Tx). In 2017, I was team leader of Desert Lion: the IAS-Lab team that participated in the Mohamed Bin Zayed International Robotics Challenge (MBZIRC), winning third place in the Grand Challenge in collaboration with the Czech Technical University in Prague, the University of Pennsylvania, and the University of Lincoln (UK). Since 2018, I am a voting member of the IEEE P1872.2 Standard "Ontologies for Autonomous Robotics" Working Group.
			</small></h2>
		</div>
	</section>
	<!-- end about -->

	<!-- start photo -->
	<section id="photo">
		<div class="container">
			<div class="row">
				<div class="col-md-12">
					<h3>RESUMÉ</h3>
				</div>
			</div>
		</section>
		<!-- end photo -->

		<!-- start resume -->
		<section id="resume">
			<div class="container">
				<div class="row">
					<div class="col-md-12">
						<h1><span>CAREER</span></h1>
						<div class="element1">
							<div style="margin-bottom:5px; font-size: 10px;"><i>from Sept 2022</i> </div>
							<div class="wow fadeIn">POSTDOC RESEARCHER</div>
							<small><div class="wow fadeIn">Embedded Systems, Fondazione Bruno Kessler, Trento, Italy</div></small>
						</div>
						<br>
						<div class="element1">
							<div style="margin-bottom:5px; font-size: 10px;"><i>Nov 2021 - Aug 2022</i> </div>
							<div class="wow fadeIn">SENIOR SOFTWARE DEVELOPER</div>
							<small><div class="wow fadeIn">221e srl, Bergamo, Italy</div></small>
						</div>
						<br>
						<div class="element1">
							<div style="margin-bottom:5px; font-size: 10px;"><i>until Nov 2021</i> </div>
							<div class="wow fadeIn">POSTDOC AND CONTRACT PROFESSOR</div>
							<small><div class="wow fadeIn">IAS-Lab, Dept. of Information Engineering, University of Padova, Italy</div></small>
						</div>
						<br><br>
						<h1 style="text-align: right;"><span >EDUCATION</span></h1>
						<div class="element1">
							<div style="margin-bottom:5px;font-size: 10px;text-align: right;"><i>Nov 11th, 2016</i></div>
							<div style="text-align: right;" class="wow fadeIn">PH.D IN ROBOTICS</div>
							<small><div style="text-align: right;" class="wow fadeIn">Doctoral School of Science and Information Technology. Dept. of Information Engineering, University of Padova, Italy</div></small>
						</div>
						<br><br>
						<div class="element1">
							<div style="margin-bottom:5px;font-size: 10; text-align: right;"><i>Apr 24th, 2012</i></div>
							<div style="text-align: right;" class="wow fadeIn">M.SC. IN COMPUTER ENGINEERING</div>
							<small><div style="text-align: right;" class="wow fadeIn">Dept. of Information Engineering, University of Padova, Italy</div></small>
						</div>
						<br><br>
						<div class="element1">
							<div style="margin-bottom:5px;font-size: 10px; text-align: right;"><i>Sept 29th, 2009</i></div>
							<div style="text-align: right;" class="wow fadeIn">B.SC. IN COMPUTER ENGINEERING</div>
							<small><div style="text-align: right;" class="wow fadeIn">Dept. of Information Engineering, University of Padova, Italy</div></small>
						</div>
						<br><br>
						<center>
							<a href="pdf/ElisaTosello.pdf" class="btn btn-default">DOWNLOAD FULL RESUMÉ</a>
						</center>
						<br><br>
					</div>

				</div>

			</div>

		</div>

	</section>
	<!-- end resume -->

	<!-- start research -->
	<section id="research">
		<div class="container">
			<div class="row">
				<div class="col-md-12">
					<h2>RESEARCH</h2>
					<!--h2 style="text-align: justify;"><small>My research interests focus on Task and Motion Planning for Digital Industry and Robotics.
				</small></h2>
				<br-->
				<h4>CURAMI </h4>
				<h2 style="text-align: justify; line-height:10px;"><small>
					Within the context of Industry 4.0, human-robot collaboration plays a crucial role: it potentially increases the process efficiency while improving
					human operator working conditions from both an ergonomic and a self-satisfaction point of view.
					To face this challenge, CURAMI (Collaborazione Uomo-Robot per Assemblaggi Manuali Intelligenti) is a project founded by Fondazione Cariverona and the University of Padova [2020-2021].
					It aims to develop an intelligent robotic framework able to manage
					the warehouse and feed the assembly workstations in a semi-autonomous way.
					The system also assists workers during the assembly and assesses their postures in real-time through an ergonomic tool able to detect potentially
					dangerous movements and give adequate feedback. The benefits are manifold: the framework reduces human operators' fatigue, improves their comfort,
					and minimizes injury risk.
				</small></h2>
				<br>
				<h4>Deep Reinforcement Learning for Robot Task and Motion Planning</h4>
				<h2 style="text-align: justify; line-height:10px;"><small>Real-world applications suffer from uncertainty and non-determinism.
					Reinforcement Learning techniques can overcome these issues while ensuring both high performances of the robotic system
					and the generality of the proposed solution.
					Our first experiments include a new formulation of the object sorting problem. Such formulation lets the application of Deep Reinforcement Learning (DRL) techniques
					to efficiently find a feasible task plan.
					Focusing on motion planning, DRL enables robotic systems to efficiently learn high dimensional control policies.
					However, generating good DRL policies requires carefully define appropriate reward functions,
					state, and action spaces. There is no unique methodology to make these choices, and parameter tuning is time-consuming.
					Thus, we investigated how the choice of both the reward function and hyper-parameters affects the quality of the policy learned.
					With the expertise gained both on task and motion planning, we are trying to combine the aforementioned approaches to solve Task and Motion Planning problems.
				</small></h2>
				<br>
				<h4>IEEE Standard for Autonomous Robotics (AuR) Ontology</h4>
				<h2 style="text-align: justify; line-height:10px;"><small>
					I'm a voting member of the IEEE1872.2 Autonomous Robotics (AuR) Ontology Working Group. In 2022, the group published the AuR ontology standard.
					This standard is a logical extension to IEEE 1872–2015 Standard Ontologies for Robotics and Automation, Core Ontology for
					Robotics and Automation (CORA). The standard extends the CORA ontology by defining additional ontologies appropriate for AuR
					relating to:
					- the core design patterns specific to AuR in common Robotics and Automation (R&A) subdomains;
					- general ontological concepts and domain-specific axioms for AuR;
					- general use cases and/or case studies for AuR.
					This standard ontology specifies the domain knowledge needed to build autonomous systems consisting of robots that can operate in all
					classes of unstructured environments. The standard provides a unified way of representing AuR system architectures across different R&A domains,
					including, but not limited to, aerial, ground, surface, underwater, and space robots. This allows unambiguous identification of the basic hardware
					and software components necessary to provide a robot, or a group of robots, with autonomy (i.e., endow robots with the ability to perform desired
					tasks in unstructured environments without continuous explicit human guidance). The stakeholders for the standard include robot designers and builders;
					robotics researchers; robot industry experts; robot users; and policy makers.
				</small></h2>
			</div>
			<!--h2 style="line-height:13px;"><small>My research interests focus on Task and Motion Planning for Digital Industry and Robotics.</small></h2>
			<h2 style="line-height:13px;"><small>here the dDescription of some of the projects in which I am involved follows:</small></h2>
			<br>
			<div class="col-md-4" data-wow-offset="50" data-wow-delay="0.6s">
			<img class="responsive" src="images/sim_pick_aligned.png" alt="DRL-TAMP" width="320" height="200">
			<h4>Deep Reinforcement Learning for TAMP</h4>
			<h2 style="text-align: justify; line-height:10px;"><small>Real-world applications suffer from uncertainty and non-determinism.
			Reinforcement Learning (RL) techniques can overcome these issues while ensuring both high performances of the robotic system
			and the generality of the proposed solution.
			Our first experiments include a new formulation of the object sorting problem. Such formulation lets the application of DRL techniques
			to efficiently find a feasible task plan.
			Focusing on motion planning, DRL enables robotic systems to efficiently learn high dimensional control policies.
			However, generating good DRL policies requires carefully define appropriate reward functions,
			state, and action spaces. There is no unique methodology to make these choices, and parameter tuning is time-consuming.
			Thus, we investigated how the choice of both the reward function and hyper-parameters affects the quality of the policy learned.
			With the expertise gained both on task and motion planning, we are trying to combine the aforementioned approaches to solve a TAMP problem.

		</small></h2>
		<h2 style="text-align: justify; line-height:15px;"><small>Available resources:</small></h2>
		<ol style="list-style-position: inside; padding-left: 0; text-align: justify; color:#000000">
		<li><a href="https://arxiv.org/abs/2005.02632" style="color:#000000">Motion planning paper;</a></li>
		<li><a href="https://doi.org/10.1109/RO-MAN47096.2020.9223484" style="color:#000000">Task planning paper 1;</a></li>
		<li><a href="https://doi.org/10.1109/SMC.2019.8914278" style="color:#000000">Task planning paper 2;</a></li>
	</ol>

</div>

<div class="col-md-4" data-wow-offset="50" data-wow-delay="0.6s">
<img class="responsive" src="images/curami.jpg" alt="CURAMI" width="320" height="200">
<h4>CURAMI</h4>
<h2 style="text-align: justify; line-height:10px;"><small>Within the context of Industry 4.0, human-robot collaboration plays a crucial role: it potentially increases the process efficiency while improving
human operator working conditions from both an ergonomic and a self-satisfaction point of view.
To face this challenge, CURAMI (Collaborazione Uomo-Robot per Assemblaggi Manuali Intelligenti) is a project founded by Fondazione Cariverona and the University of Padova.
It aims to develop an intelligent robotic framework able to manage
the warehouse and feed the assembly workstations in a semi-autonomous way.
The system also assists workers during the assembly and assesses their postures in real-time through an ergonomic tool able to detect potentially
dangerous movements and give adequate feedback. The benefits are manifold: the framework reduces human operators' fatigue, improves their comfort,
and minimizes injury risk.
Within the project, I’m responsible of the task scheduling and motion planning activity.  </small></h2>
<h2 style="text-align: justify; line-height:15px;"><small>Available resources:</small></h2>
<ol style="list-style-position: inside; padding-left: 0; text-align: justify; color:#000000">
<li><a href="https://github.com/CURAMI" style="color:#000000">GitHub link</a></li>
</ol>


</div>

<div class="col-md-4" data-wow-offset="50" data-wow-delay="0.6s">
<img class="responsive" src="images/axioms.jpg" alt="IEEE-Standard" width="320" height="200">
<h4>IEEE Standards</h4>
<h2 style="text-align: justify; line-height:10px;"><small>
I'm a voting member of the IEEE1872.2 Autonomous Robotics (AuR) Ontology Working Group. The group has recently developed the AuR ontology standard.
This standard is a logical extension to IEEE 1872–2015 Standard Ontologies for Robotics and Automation, core ontology or
robotics and automation (CORA). The standard extends the CORA ontology by defining additional ontologies appropriate for AuR
relating to:
- the core design patterns specific to AuR in common Robotics and Automation (R&A) subdomains;
- general ontological concepts and domain-specific axioms for AuR;
- general use cases and/or case studies for AuR.
This standard ontology specifies the domain knowledge needed to build autonomous systems consisting of robots that can operate in all
classes of unstructured environments. The standard provides a unified way of representing AuR system architectures across different R&A domains,
including, but not limited to, aerial, ground, surface, underwater, and space robots. This allows unambiguous identification of the basic hardware
and software components necessary to provide a robot, or a group of robots, with autonomy (i.e., endow robots with the ability to perform desired
tasks in unstructured environments without continuous explicit human guidance). The stakeholders for the standard include robot designers and builders;
robotics researchers; robot industry experts; robot users; and policy makers.</small></h2>
<h2 style="text-align: justify; line-height:15px;"><small>Available resources:</small></h2>
<ol style="list-style-position: inside; padding-left: 0; text-align: justify; color:#000000">
<li><a href="https://doi.org/10.1109/MRA.2021.3095993" style="color:#000000">RAS Magazine article</a></li>
</ol>

</div-->
</div>
</div>
</section>
<!-- end research -->

<!-- start code -->
<section id="code">
<div class="container">
	<div class="row">
		<div class="col-md-12">
			<div class="element1">
				<h2>AVAILABLE CODE</h2>
				<br>
				<ol style="list-style-position: inside; padding-left: 0; text-align: justify; color:black;">
					The links to the GitHub repositories of the main projects in which I'm (or I was) involved follow. Each repository is
					equipped with README.md files containing the instructions to faithfully replicate
					its content or simply exploit and adapt part of it to the user goals.
					<br><br>
					<li><b><a href="http://wiki.ros.org/muse_v2_driver"> Muse V2 Driver</a></b>: The driver package for the 221e MUltiSEnsor (MUSE) device. </li>
					<br>
					<li><b><a href="http://wiki.ros.org/mitch_v2_driver"> Mitch V2 Driver</a></b>: The driver package for the 221e Multisensor InerTial CHamaleon (MITCH) V2 device. </li>
					<br>
					<li><b><a href="https://github.com/CURAMI"> CURAMI</a></b>: (Collaborazione Uomo-Robot per Assemblaggi Manuali Intelligenti): Project supported by Fondazione Cariverona and the University of Padova on human-robot collaboration for intelligent assembly tasks.</li>
					<br>
					<li><b><a href="https://github.com/Robin4-0"> RobIn4.0</a></b>: The Autonomous Robotics class assignment. </li>
				</ol>
			</h2>
		</div>
	</div>
</div>
</div>
</section>
<!-- end code -->

<!-- start teaching -->
<section id="teaching">
<div class="container">
	<div class="row">
		<div class="col-md-12">
			<div class="element1">
				<h2>TEACHING</h2>
				<br>
				<ol style="list-style-position: inside; padding-left: 0; text-align: justify; color:#ffffff;">
					Since the beginning of my PhD, I have been tutoring and teaching students and companies.
					<br><br>
					From 2017 to 2020, I taught 3 of the 9 credits of the Autonomous Robotics course: a course in the second year of the Master of Science in Computer Engineering at the University of Padova (Italy).
					The course covers the basic principles for endowing autonomous robots with perception, planning, and decision-making capabilities.
					A set of lectures provides students with a strong theoretical background on these concepts. A laboratory assignment, namely <a href="https://github.com/Robin4-0" style="color:yellow">RobIn 4.0</a>,
					asks students to apply the learned knowledge to challenging multi-robot applications using the Robot Operating System (ROS).
					Students have to program the supply of an assembly workstation through the cooperation of a mobile and a manipulator robot.
					At the end, a challenge is organized to make the learning experience more extensive while motivating students to propose innovative solutions.
					In this context, my role was dual:
					<br><br>

					<li><b>Theory</b>: introducing students to robot Kinematics and Dynamics, Motion Planning, Task Planning, and Cloud Robotics.</li>
					<li><b>Lab</b>: introducing students to the ROS Framework by overviewing its architecture and proposing practical tutorials on perception, manipulation, and navigation  </li>
				</ol>
				<br>
				The following video shows the solution proposed by a group of students in A.Y. 2019/2020. </p>
			</div>
			<div class="container2">
				<iframe class="responsive-iframe" src="video/Robin4.0.mp4"></iframe>
			</div>
		</div>
	</div>
</div>
</section>
<!-- end teaching -->


<!-- start publications -->
<section id="publications">
<div class="container">
	<div class="row">
		<div class="col-md-12">
			<h2>LIST OF PUBLICATIONS</h2>
			<br>
			<center>
				<a href="pdf/Publications.pdf" class="btn btn-default">DOWNLOAD LIST OF PUBLICATIONS</a>
			</center>
			<br><br>
			<div class="element1">
				<h1><span>STANDARDS</span></h1>

				<ol style="list-style-position: inside; padding-left: 0; text-align: justify; ">
					<li style="margin-bottom: 0.2cm;"><b>IEEE Standard for Autonomous Robotics (AuR) Ontology</b>. 2022. IEEE Standard number P1872.2.</li>
					<p id="hidden-div-abstract-s0" class="well" style="display: none">
This standard extends IEEE Std 1872-2015, IEEE Standard for Ontologies for Robotics and Automation, to represent additional domain-specific concepts, definitions, and axioms commonly used in Autonomous Robotics (AuR). This standard is general and can be used in many ways--for example, to specify the domain knowledge needed to unambiguously describe the design patterns of AuR systems; to represent AuR system architectures in a unified way; or as a guideline to build autonomous systems consisting of robots operating in various environments.
					</p>
					<button onclick="show('abstract-s0')">abstract</button>
					<button onclick="location.href='https://standards.ieee.org/ieee/1872.2/7094/';">standard</button>
				</ol>
				<br>
				<h1><span>JOURNALS</span></h1>
				<ol style="list-style-position: inside; padding-left: 0; text-align: justify;">
					<li style="margin-bottom: 0.2cm;">A. Gottardi, S. Tortora*, E. Tosello*, E. Menegatti. <b>Shared Control in Robot Teleoperation With Improved Potential Fields</b>. IEEE Transactions on Human-Machine Systems, vol. 52, no. 3, pp. 410-422, June 2022, doi: 10.1109/THMS.2022.3155716. </li>
					<pre id="hidden-div-bibtex-j0" style="display: none">
@ARTICLE{9734752,
author={Gottardi, Alberto and Tortora, Stefano and Tosello, Elisa and Menegatti, Emanuele},
journal={IEEE Transactions on Human-Machine Systems},
title={Shared Control in Robot Teleoperation With Improved Potential Fields},
year={2022},
volume={52},
number={3},
pages={410-422},
doi={10.1109/THMS.2022.3155716}}</pre>
					<p id="hidden-div-abstract-j0" class="well" style="display: none">
In shared control teleoperation, the robot assists the user in accomplishing the desired task. Rather than simply executing the user’s command, the robot attempts to integrate it with information from the environment, such as obstacle and/or goal locations, and it modifies its behavior accordingly. In this article, we propose a real-time shared control teleoperation framework based on an artificial potential field approach improved by the dynamic generation of escape points around the obstacles. These escape points are virtual attractive points in the potential field that the robot can follow to overcome the obstacles more easily. The selection of which escape point to follow is done in real time by solving a soft-constrained problem optimizing the reaching of the most probable goal, estimated from the user’s action. Our proposal has been extensively compared with two state-of-the-art approaches in a static cluttered environment and a dynamic setup with randomly moving objects. Experimental results showed the efficacy of our method in terms of quantitative and qualitative metrics. For example, it significantly decreases the time to complete the tasks and the user’s intervention, and it helps reduce the failure rate. Moreover, we received positive feedback from the users that tested our proposal. Finally, the proposed framework is compatible with both mobile and manipulator robots.
					</p>
					<button onclick="show('bibtex-j0')">bibtex</button>
					<button onclick="show('abstract-j0')">abstract</button>
					<button onclick="location.href='https://ieeexplore.ieee.org/document/9734752';">paper</button>
					<br><br>
					<li style="margin-bottom: 0.2cm;">P. J.S. Gonçalves, A. Olivares Alarcos, J. Bermejo-Alonso, S. Borgo, M. Diab, M. Habib, H. Kumar Nakawala,
						S. V. Ragavan, R. Sanz, E. Tosello, H. Li. <b>IEEE Standard for Autonomous Robotics Ontology</b>. In IEEE Robotics & Automation Magazine, vol. 28, no. 3, pp. 171-173, Sept. 2021.</li>
						<pre id="hidden-div-bibtex-j1" style="display: none">
@ARTICLE{9535344,
author={Gonçalves, Paulo J.S. and Olivares-Alarcos, Alberto and Bermejo-Alonso, Julita and Borgo, Stefano and Diab, Mohammed and Habib, Maki and Nakawala, Hirenkumar and Ragavan, S. Veera and Sanz, Ricardo and Tosello, Elisa and Li, Howard},
journal={IEEE Robotics & Automation Magazine},
title={IEEE Standard for Autonomous Robotics Ontology [Standards]},
year={2021},
volume={28},
number={3},
pages={171-173},
doi={10.1109/MRA.2021.3095993}}</pre>
						<p id="hidden-div-abstract-j1" class="well" style="display: none">
The IEEE1872.2 Autonomous Robotics (AuR) Ontology Working Group has recently developed the AuR ontology standard. This standard is a logical extension to IEEE 1872–2015 Standard Ontologies for Robotics and Automation, core ontology or robotics and automation (CORA).
						</p>
						<button onclick="show('bibtex-j1')">bibtex</button>
						<button onclick="show('abstract-j1')">abstract</button>
						<button onclick="location.href='https://doi.org/10.1109/MRA.2021.3095993';">paper</button>
						<br><br>
						<li style="margin-bottom: 0.2cm;">N. Castaman, E. Tosello, M. Antonello, N. Bagarello, S. Gandin, M. Carraro, M. Munaro, R. Bortoletto, S. Ghidoni, E. Menegatti, E. Pagello. (2021) <b>RUR53: an unmanned ground vehicle for navigation, recognition, and manipulation</b>. Advanced Robotics, 35:1, 1-18.</li>
						<pre id="hidden-div-bibtex-j2" style="display: none">
@article{doi:10.1080/01691864.2020.1833752,
author = {Nicola Castaman and Elisa Tosello and Morris Antonello and Nicola Bagarello and Silvia Gandin and Marco Carraro and Matteo Munaro and Roberto Bortoletto and Stefano Ghidoni and Emanuele Menegatti and Enrico Pagello},
title = {RUR53: an unmanned ground vehicle for navigation, recognition, and manipulation},
journal = {Advanced Robotics},
volume = {35},
number = {1},
pages = {1-18},
year  = {2021},
publisher = {Taylor & Francis},
doi = {10.1080/01691864.2020.1833752}}
						</pre>
						<p id="hidden-div-abstract-j2" class="well" style="display: none">
This paper proposes RUR53: an Unmanned Ground Vehicle able to navigate through, identify, and reach areas of interest. There, it can recognize, localize, and manipulate work tools to perform both indoor and outdoor complex tasks. Indeed, a wide range of sensors composes the robot and enables it to perceive vast workspaces, reach distant targets, and face the uncertainties of the real world. Precise object detection is also guaranteed, essential to manipulate objects of different shapes and materials. Moreover, a customized 3-finger gripper makes the gripping mode suitable for any lightweight object. Two modalities are proposed: autonomous and teleoperated, letting both unskilled and skilled human operators easily adapt the system to complete personalized tasks. The paper exhaustively describes RUR53 architecture and demonstrates its good performance while executing both indoor and outdoor navigation and manipulation tasks. A specific case study is described where the proposed modular architecture allows to easily switch to a semi-teleoperated mode: the 2017 Mohamed Bin Zayed International Robotics Challenge, where our team ranked third in the Grand Challenge in collaboration with the Czech Technical University in Prague, the University of Pennsylvania, and the University of Lincoln (UK).
						</p>
						<button onclick="show('bibtex-j2')">bibtex</button>
						<button onclick="show('abstract-j2')">abstract</button>
						<button onclick="location.href='https://doi.org/10.1080/01691864.2020.1833752';">paper</button>
						<br><br>
						<li style="margin-bottom: 0.2cm;">E. P. de Freitas, J. I. Olszewska, J. L. Carbonera, S. R. Fiorini, A. Khamis, S. V. Ragavan, M. Barreto, E. Prestes, M. K. Habib, S. Redfield, A. Chibani, P. Goncalves, J. Bermejo-Alonso, R. Sanz, E. Tosello, H. Li, A. Olivares-Alarco. <b>Ontological concepts for information sharing in cloud robotics</b>. J Ambient Intell Human Comput (2020).</li>
						<pre id="hidden-div-bibtex-j3" style="display: none">
@article{doi:10.1007/s12652-020-02150-4,
author = {Edison Pignaton de Freitas and Joanna Isabelle Olszewska and Joel Luís Carbonera and et al. },
title = {Ontological concepts for information sharing in cloud robotics},
journal = {Journal of Ambient Intelligence and Humanized Computing },
year  = {2020},
publisher = {Springer},
doi = {10.1007/s12652-020-02150-4}}</pre>
						<p id="hidden-div-abstract-j3" class="well" style="display: none">
Recent research and developments in cloud robotics (CR) require appropriate knowledge representation to ensure interoperable data, information, and knowledge sharing within cloud infrastructures. As an important branch of the Internet of Things (IoT), these demands to advance it forward motivates academic and industrial sectors to invest on it. The IEEE ’Ontologies for Robotics and Automation’ Working Group (ORA WG) has been developing standard ontologies for different robotic domains, including industrial and autonomous robots. The use of such robotic standards has the potential to benefit the Cloud Robotic Community (CRC) as well, supporting the provision of ubiquitous intelligent services by the CR-based systems. This paper explores this potential by developing an ontological approach for effective information sharing in cloud robotics scenarios. It presents an extension to the existing ontological standards to cater for the CR domain. The use of the new ontological elements is illustrated through its use in a couple of CR case studies. To the best of our knowledge, this is the first work ever that implements an ontology comprising concepts and axioms applicable to the CR domain.
						</p>
						<button onclick="show('bibtex-j3')">bibtex</button>
						<button onclick="show('abstract-j3')">abstract</button>
						<button onclick="location.href='https://doi.org/10.1007/s12652-020-02150-4';">paper</button>
						<br><br>
						<li style="margin-bottom: 0.2cm;">S. Michieletto, E. Tosello, E. Pagello, E. Menegatti. <b>Teaching humanoid robotics by means of human teleoperation through RGB-D sensors</b>. Robotics and Autonomous Systems, Volume 75, Part B, 2016, Pages 671-678, ISSN 0921-8890.</li>
						<pre id="hidden-div-bibtex-j4" style="display: none">
@article{MICHIELETTO2016671,
title = {Teaching humanoid robotics by means of human teleoperation through RGB-D sensors},
journal = {Robotics and Autonomous Systems},
volume = {75},
pages = {671-678},
year = {2016},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2015.09.023},
author = {Stefano Michieletto and Elisa Tosello and Enrico Pagello and Emanuele Menegatti}}</pre>
						<p id="hidden-div-abstract-j4" class="well" style="display: none">
This paper presents a graduate course project on humanoid robotics offered by the University of Padova. The target is to safely lift an object by teleoperating a small humanoid. Students have to map human limbs into robot joints, guarantee the robot stability during the motion, and teleoperate the robot to perform the correct movement. We introduce the following innovative aspects with respect to classical robotic classes: i) the use of humanoid robots as teaching tools; ii) the simplification of the stable locomotion problem by exploiting the potential of teleoperation; iii) the adoption of a Project-Based Learning constructivist approach as teaching methodology. The learning objectives of both course and project are introduced and compared with the students’ background. Design and constraints students have to deal with are reported, together with the amount of time they and their instructors dedicated to solve tasks. A set of evaluation results are provided in order to validate the authors’ purpose, including the students’ personal feedback. A discussion about possible future improvements is reported, hoping to encourage further spread of educational robotics in schools at all levels.
						</p>
						<button onclick="show('bibtex-j4')">bibtex</button>
						<button onclick="show('abstract-j4')">abstract</button>
						<button onclick="location.href='https://doi.org/10.1016/j.robot.2015.09.023';">paper</button>
					</ol>
					<br>
					<h1><span>CONFERENCES</span></h1>

					<ol style="list-style-position: inside; padding-left: 0; text-align: justify;">
						<li style="margin-bottom: 0.2cm;">A. Franceschetti*, E. Tosello*, N. Castaman, S. Ghidoni. (2022). <b>Robotic Arm Control and Task Training Through Deep Reinforcement Learning</b>. In: Ang Jr, M.H., Asama, H., Lin, W., Foong, S. (eds) Intelligent Autonomous Systems 16. IAS 2021. Lecture Notes in Networks and Systems, vol 412. Springer, Cham. https://doi.org/10.1007/978-3-030-95892-3_41</li>
						<pre id="hidden-div-bibtex-c0" style="display: none">
@InProceedings{10.1007/978-3-030-95892-3_41,
author="Franceschetti, Andrea and Tosello, Elisa and Castaman, Nicola and Ghidoni, Stefano",
editor="Ang Jr, Marcelo H. and Asama, Hajime and Lin, Wei and Foong, Shaohui",
title="Robotic Arm Control and Task Training Through Deep Reinforcement Learning",
booktitle="Intelligent Autonomous Systems 16",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="532--550",
isbn="978-3-030-95892-3"}}</pre>
						<p id="hidden-div-abstract-c0" class="well" style="display: none">
Deep Reinforcement Learning (DRL) is a promising Machine Learning technique that enables robotic systems to efficiently learn high dimensional control policies. However, generating good policies requires carefully define appropriate reward functions, state, and action spaces. There is no unique methodology to make these choices, and parameter tuning is time-consuming. In this paper, we investigate how the choice of both the reward function and hyper-parameters affects the quality of the policy learned. To this aim, we compare four DRL algorithms when learning continuous torque control policies for manipulation tasks via a model-free approach. In detail, we simulate one manipulator robot and formulate two tasks: a random target reaching and a pick{\&}place application, each with two different reward functions. Then, we select the algorithms, multiple hyper-parameters, and exhaustively compare their learning performance across the two tasks. Finally, we include the simulated and real-world execution of our best policies. The obtained performance demonstrates the validity of our proposal. Users can follow our approach when selecting the best-performing algorithm according to the assignment. Moreover, they can exploit our results to solve the same tasks, even with other manipulator robots. Generated policies will be easily portable to a physical setup while guaranteeing a perfect match between the simulated and real behaviors.
						</p>
						<button onclick="show('bibtex-c0')">bibtex</button>
						<button onclick="show('abstract-c0')">abstract</button>
						<button onclick="location.href='https://link.springer.com/chapter/10.1007/978-3-030-95892-3_41';">paper</button>
						<br><br>

						<li style="margin-bottom: 0.2cm;">L. Tagliapietra*, E. Tosello*, E. Pagello, E. Menegatti. (2022). <b>A Planning Domain Definition Language Generator, Interpreter, and Knowledge Base for Efficient Automated Planning</b>. In: Ang Jr, M.H., Asama, H., Lin, W., Foong, S. (eds) Intelligent Autonomous Systems 16. IAS 2021. Lecture Notes in Networks and Systems, vol 412. Springer, Cham. https://doi.org/10.1007/978-3-030-95892-3_43 </li>
						<pre id="hidden-div-bibtex-c1" style="display: none">
@InProceedings{10.1007/978-3-030-95892-3_43,
author="Tagliapietra, Luca and Tosello, Elisa and Pagello, Enrico and Menegatti, Emanuele",
editor="Ang Jr, Marcelo H. and Asama, Hajime and Lin, Wei and Foong, Shaohui",
title="A Planning Domain Definition Language Generator, Interpreter, and Knowledge Base for Efficient Automated Planning",
booktitle="Intelligent Autonomous Systems 16",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="563--579",
isbn="978-3-030-95892-3"}}
						</pre>
						<p id="hidden-div-abstract-c1" class="well" style="display: none">
The Planning Domain Definition Language (PDDL) successfully encodes classical planning tasks by easily describing objects, actions, and states in many planning domains. PDDL also describes domains, but they include only predefined sets of actions that can solve problems in a finite set of states. Indeed, the PDDL structure disables the processing of single predicates and operators. As a consequence, they cannot be arbitrarily composed to model new domains. To overcome these limitations, we propose a domain-independent, general-purpose knowledge design and task planning system based on the combination of a PDDL generator and interpreter and a Knowledge Base. The former builds planning data structures, where every object is a PDDL token independent of its original domain. It also allows merging these objects to formulate new PDDL domains and problems, ensuring consistency and validity of generated definitions. Their resolution is based on a powerful object-based reasoning instead of an inefficient lexical-based one. The latter contains the necessary relationships and representations to allow data storing and reusability. Their combination enables the storage, interpretation, and reuse of planning data, resulting in integration between the planning process and description logic reasoning. The overall system guarantees a flexible adaptation of the computed planning domains to changing environmental conditions, agent capabilities, and assigned tasks, promoting effective sharing and reuse of domain knowledge across different systems and applications.
						</p>
						<button onclick="show('bibtex-c1')">bibtex</button>
						<button onclick="show('abstract-c1')">abstract</button>
						<button onclick="location.href='https://link.springer.com/chapter/10.1007/978-3-030-95892-3_43';">paper</button>
						<br><br>

						<li style="margin-bottom: 0.2cm;">L. Tagliapietra*, E. Tosello*, E. Menegatti. <b>CURAMI: Human-Robot Collaboration for Intelligent Assembly Tasks</b>. 2a Conferenza Italiana di Robotica e Macchine
							Intelligenti (I-RIM 2020); Proceedings of. Dic 10-12. 2020. Online.</li>
							<br><br>

							<li style="margin-bottom: 0.2cm;">G. Nicola*, L. Tagliapietra*, E. Tosello*, N. Navarin, S. Ghidoni, E. Menegatti. <b>Robotic
								Object Sorting via Deep Reinforcement Learning: a generalized approach</b>. The
								29th IEEE International Conference on Robot and Human Interactive Communication
								(IEEE ROMAN 2020); Proceedings of. Aug 31-Sept 4, 2020. Naple (Italy).</li>
								<pre id="hidden-div-bibtex-c3" style="display: none">
@INPROCEEDINGS{9223484,
author={Nicola, Giorgio and Tagliapietra, Luca and Tosello, Elisa and Navarin, Nicolò and Ghidoni, Stefano and Menegatti, Emanuele},
booktitle={2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},
title={Robotic Object Sorting via Deep Reinforcement Learning: a generalized approach},
year={2020},
volume={},
number={},
pages={1266-1273},
doi={10.1109/RO-MAN47096.2020.9223484}}</pre>
								<p id="hidden-div-abstract-c3" class="well" style="display: none">
This work proposes a general formulation for the Object Sorting problem, suitable to describe any non-deterministic environment characterized by friendly and adversarial interference. Such an approach, coupled with a Deep Reinforcement Learning algorithm, allows training policies to solve different sorting tasks without adjusting the architecture or modifying the learning method. Briefly, the environment is subdivided into a clutter, where objects are freely located, and a set of clusters, where objects should be placed according to predefined ordering and classification rules. A 3D grid discretizes such environment: the properties of an object within a cell depict its state. Such attributes include object category and order. A Markov Decision Process formulates the problem: at each time step, the state of the cells fully defines the environment's one. Users can custom-define object classes, ordering priorities, and failure rules. The latter by assigning a non-uniform risk probability to each cell. Performed experiments successfully trained and validated a Deep Reinforcement Learning model to solve several sorting tasks while minimizing the number of moves and failure probability. Obtained results demonstrate the capability of the system to handle non-deterministic events, like failures, and unpredictable external disturbances, like human user interventions.
								</p>
								<button onclick="show('bibtex-c3')">bibtex</button>
								<button onclick="show('abstract-c3')">abstract</button>
								<button onclick="location.href='https://doi.org/10.1109/RO-MAN47096.2020.9223484';">paper</button>
								<br><br>

								<li style="margin-bottom: 0.2cm;">F. Ceola, E. Tosello, L. Tagliapietra, G. Nicola, S. Ghidoni. <b>Robot Task Planning via
									Deep Reinforcement Learning: a Tabletop Object Sorting Application</b>. 2019
									IEEE International Conference on Systems, Man, and Cybernetics (IEEE SMC 2019);
									Proceedings of. Oct 6-9, 2019. Bari (Italy).</li>
									<pre id="hidden-div-bibtex-c4" style="display: none">
@INPROCEEDINGS{8914278,
author={Ceola, Federico and Tosello, Elisa and Tagliapietra, Luca and Nicola, Giorgio and Ghidoni, Stefano},
booktitle={2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)},
title={Robot Task Planning via Deep Reinforcement Learning: a Tabletop Object Sorting Application},
year={2019},
volume={},
number={},
pages={486-492},
doi={10.1109/SMC.2019.8914278}}
									</pre>
									<p id="hidden-div-abstract-c4" class="well" style="display: none">
This paper proposes a Deep Reinforcement Learning powered approach for tabletop object sorting. Once perceived the environment, the system creates a semantic representation of the scene, describing the pose and category of each recognized object. This image is then provided as input to the trained Deep Neural Network in charge of choosing the correct action to be performed to successfully achieve the sorting task. Obtained results prove the capability of the proposed system, including its intrinsic robustness to failures and unpredictable interactions with humans or other environmental agents. Moreover, the use of semantic images makes the Deep Neural Network independent from the type of objects to be sorted and from their final placement location. Finally, the system is scalable, being capable of sorting as many known objects as recognized by the perception system. Currently, the system can sort objects belonging to two predefined categories while treating all the others as obstacles. Future works will extend the system making it capable of sorting potentially any type and number of object categories.
									</p>
									<button onclick="show('bibtex-c4')">bibtex</button>
									<button onclick="show('abstract-c4')">abstract</button>
									<button onclick="location.href='https://doi.org/10.1109/SMC.2019.8914278';">paper</button>
									<br><br>

									<li style="margin-bottom: 0.2cm;">L. Fortunati, J. Höflich, A. M. Manganelli, E. Tosello, G. Ferrin. <b>The uncanny theory
										under scrutiny</a></b>. 10th Italian Forum Ambient Assisted Living (ForItAAL); Proceedings
										of. Jun 19 - 21, 2019. Ancona (Italy).</li>
										<br><br>

										<li style="margin-bottom: 0.2cm;">E. Tosello, N. Castaman, E. Menegatti. <b>Using robotics to train students for Industry 4.0</b>. International Federation of Automatic Control Advances in Control Education
											Symposium (IFAC-ACE); Proceedings of. Jul 7 - 9, 2019. Philadelphia, PD (USA).</li>
											<pre id="hidden-div-bibtex-c6" style="display: none">
@article{TOSELLO2019153,
title = {Using robotics to train students for Industry 4.0},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {9},
pages = {153-158},
year = {2019},
note = {12th IFAC Symposium on Advances in Control Education ACE 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.08.185},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319305221},
author = {Elisa Tosello and Nicola Castaman and Emanuele Menegatti}}</pre>
											<p id="hidden-div-abstract-c6" class="well" style="display: none">
This paper presents the master course on Autonomous Robotics that we offer at the School of Engineering of the University of Padova (Italy). Its novelty is the assignment of a lab project carefully designed to train students on autonomous and industrial robotics in the framework of Industry 4.0: the “Industry 4.0 Robotics Challenge”. Students have to program both a manipulator and a mobile robot, together with a 3D vision system, in order to collaborate in the fulfillment of a pick-place-transport industrial task. We adopt a constructionist approach: project-based learning and team-based learning are applied to robotics and Industry 4.0. The project is organized as a challenge to motivate students to propose innovative ideas. A survey on students’ satisfaction is reported at the end of the paper. We made the description of both the hardware and software setup, together with tutorials and wikis, publicly available to let other robotics instructors replicate our proposal and make it a point of reference for teaching robotics in the frame of Industry 4.0.
											</p>
											<button onclick="show('bibtex-c6')">bibtex</button>
											<button onclick="show('abstract-c6')">abstract</button>
											<button onclick="location.href='https://doi.org/10.1016/j.ifacol.2019.08.185';">paper</button>
											<br><br>

											<li style="margin-bottom: 0.2cm;">A. Dalla Libera, E. Tosello, S. Ghidoni, G. Pillonetto, R. Carli. <b>Proprioceptive Robot
												Collision Detection through Gaussian Process Regression</b>. 2019 American Control
												Conference (ACC); Proceedings of. Jul 10 - 19, 2019. Philadelphia, PA (USA).</li>
												<pre id="hidden-div-bibtex-c7" style="display: none">
@INPROCEEDINGS{8814361,
author={Dalla Libera, Alberto and Tosello, Elisa and Pillonetto, Gianluigi and Ghidoni, Stefano and Carli, Ruggero},
booktitle={2019 American Control Conference (ACC)},
title={Proprioceptive Robot Collision Detection through Gaussian Process Regression},
year={2019},
volume={},
number={},
pages={19-24},
doi={10.23919/ACC.2019.8814361}}</pre>
												<p id="hidden-div-abstract-c7" class="well" style="display: none">
This paper proposes a proprioceptive collision detection algorithm based on Gaussian Regression. Compared to sensor-based collision detection and other proprioceptive algorithms, the proposed approach has minimal sensing requirements, since only the currents and the joint configurations are needed. The algorithm extends the standard Gaussian Process models adopted in learning the robot inverse dynamics, using a more rich set of input locations and an ad-hoc kernel structure to model the complex and non-linear behaviors due to frictions in quasi-static configurations. Tests performed on a Universal Robots UR10 show the effectiveness of the proposed algorithm to detect when a collision has occurred.
												</p>
												<button onclick="show('bibtex-c7')">bibtex</button>
												<button onclick="show('abstract-c7')">abstract</button>
												<button onclick="location.href='https://doi.org/10.23919/ACC.2019.8814361';">paper</button>
												<br><br>

												<li style="margin-bottom: 0.2cm;">E. Tosello, N. Castaman, S. Michieletto E. Menegatti. <b>Teaching Robot Programming
													for Industry 4.0</b>. International Conference Educational Robotics 2018 (EduRobotics
													2018). October 11, 2018. Rome (Italy).</li>
													<pre id="hidden-div-bibtex-c8" style="display: none">
@InProceedings{10.1007/978-3-030-18141-3_9,
author="Tosello, Elisa and Castaman, Nicola and Michieletto, Stefano and Menegatti, Emanuele",
editor="Moro, Michele and Alimisis, Dimitris and Iocchi, Luca",
title="Teaching Robot Programming for Industry 4.0",
booktitle="Educational Robotics in the Context of the Maker Movement",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="107--119",
isbn="978-3-030-18141-3"}</pre>
													<p id="hidden-div-abstract-c8" class="well" style="display: none">
This paper presents a master course project on intelligent robotics offered by the University of Padova (Italy). The goal is that of training Master students for Industry 4.0 by offering a multidisciplinary laboratory experience in which two robots and a human must collaborate to fulfill an assembly task: one manipulator robot has to recognize some pieces on a table, manipulate them, and place them on the top of a mobile robot. The mobile robot has to carry these pieces within an arena until reaching an assembly station where the human operator will complete the assembly task. Through our constructivist approach, students learn how to face a rapidly evolving discipline requiring the integration and cooperation of multiple subsystems to create complex behaviors. They learn how to program autonomous robots by using the Robot Operating System. They learn how to exhaustively document their activity explaining design choices, the benefits and the limits of their approaches, as well as proposing new solutions to overcome these limitations. They learn how to properly implement and comment code as well as create step-by-step instructions to enable future users to reproduce their systems. The project is organized as a challenge to motivate students to propose innovative ideas: students are subdivided into teams, every team proposes its own solution, and different scores are assigned according to the proposed difficulty level and the required working time.",
													</p>
													<button onclick="show('bibtex-c8')">bibtex</button>
													<button onclick="show('abstract-c8')">abstract</button>
													<button onclick="location.href='https://doi.org/10.1007/978-3-030-18141-3_9';">paper</button>
													<br><br>

													<li style="margin-bottom: 0.2cm;">N. Castaman, E. Tosello, E. Pagello. <b>Conditional Task and Motion Planning
														through an Effort-based Approach</b>. Simulation, Modeling, and Programming for
														Autonomous Robots. IEEE International Conference, SIMPAR 2018; Proceedings of. May
														16-19, 2018. Brisbane (Australia).</li>
														<pre id="hidden-div-bibtex-c9" style="display: none">
@INPROCEEDINGS{8376270,
author={Castaman, Nicola and Tosello, Elisa and Pagello, Enrico},
booktitle={2018 IEEE International Conference on Simulation, Modeling, and Programming for Autonomous Robots (SIMPAR)},
title={Conditional task and motion planning through an effort-based approach},
year={2018},
volume={},
number={},
pages={49-54},
doi={10.1109/SIMPAR.2018.8376270}}
														</pre>
														<p id="hidden-div-abstract-c9" class="well" style="display: none">
This paper proposes a preliminary work on a Conditional Task and Motion Planning algorithm able to find a plan that minimizes robot efforts while solving assigned tasks. Unlike most of the existing approaches that replan a path only when it becomes unfeasible (e.g., no collision-free paths exist), the proposed algorithm takes into consideration a replanning procedure whenever an effort-saving is possible. The effort is here considered as the execution time, but it is extensible to the robot energy consumption. The computed plan is both conditional and dynamically adaptable to the unexpected environmental changes. Based on the theoretical analysis of the algorithm, authors expect their proposal to be complete and scalable. In progress experiments aim to prove this investigation.
														</p>
														<button onclick="show('bibtex-c9')">bibtex</button>
														<button onclick="show('abstract-c9')">abstract</button>
														<button onclick="location.href='https://doi.org/10.1109/SIMPAR.2018.8376270';">paper</button>
														<br><br>

														<li style="margin-bottom: 0.2cm;">E. Tosello, Z. Fan, A. C. Gatto, E. Pagello. <b>Cloud-Based Task Planning for Smart
															Robots</b>. Intelligent Autonomous Systems 14: Proceedings of the 14th International
															Conference IAS-14. July 3-7, 2016. Shanghai (China). ISBN: 978-3-319-48036-7. pp.
															285-300.</li>
															<pre id="hidden-div-bibtex-c10" style="display: none">
@InProceedings{10.1007/978-3-319-48036-7_21,
author="Tosello, Elisa and Fan, Zhengjie and Castro, Alejandro Gatto and Pagello, Enrico",
editor="Chen, Weidong and Hosoda, Koh and Menegatti, Emanuele and Shimizu, Masahiro and Wang, Hesheng",
title="Cloud-Based Task Planning for Smart Robots",
booktitle="Intelligent Autonomous Systems 14",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="285--300",
isbn="978-3-319-48036-7"}</pre>
															<p id="hidden-div-abstract-c10" class="well" style="display: none">
This paper proposes an Open Semantic Framework for knowledge acquisition of cognitive robots performing manipulation tasks. It integrates a Cloud-based Engine, which extracts discriminative features from the objects and generates their manipulation actions, and an Ontology, where the Engine saves data for future accesses. The Engine offloads robots by transferring computation on the Cloud. The Ontology favors knowledge sharing among manipulator robots by defining a common manipulation vocabulary. It extends the work proposed by the IEEE RAS Ontology for Robotics and Automation Working Group by covering the manipulation task domain. During ontological data insertion, data duplication is avoided by providing a novel efficient interlinking algorithm. During their retrieval, visual data processing is optimized by using a cascade hashing algorithm that intelligently accesses data. No training is required for object recognition and manipulation because of the adoption of a human-robot cooperation. The framework is based on the open-source Robot Operating System.
															</p>
															<button onclick="show('bibtex-c10')">bibtex</button>
															<button onclick="show('abstract-c10')">abstract</button>
															<button onclick="location.href='https://doi.org/10.1007/978-3-319-48036-7_21';">paper</button>
															<br><br>
															<li style="margin-bottom: 0.2cm;">N. Castaman, E. Tosello, E. Pagello. <b>A sampling-based Tree Planner for Navigation
																Among Movable Obstacles</b>. ISR 2016; 47th International Symposium on Robotics;
																Proceedings of. June 21-22, 2016. Munich (Germany).</li>
																<pre id="hidden-div-bibtex-c11" style="display: none">
@INPROCEEDINGS{7559130,
author={Castaman, Nicola and Tosello, Elisa and Pagello, Enrico},
booktitle={Proceedings of ISR 2016: 47st International Symposium on Robotics},
title={A Sampling-Based Tree Planner for Navigation Among Movable Obstacles},
year={2016},
volume={},
number={},
pages={1-8},
doi={}}</pre>
																<p id="hidden-div-abstract-c11" class="well" style="display: none">
This paper proposes a planner that solves Navigation Among Movable Obstacles problems giving robots the ability to reason about the environment and choose when manipulating obstacles. It finds a path from a robot start configuration S to a goal configuration G taking into consideration the possibility of moving objects if G cannot be reached or if moving objects may significantly shorten the path. The planner combines the A*-Search and the exploration strategy of the Kinodynamic Motion Planning by Interior-Exterior Cell Exploration algorithm. It is locally optimal and independent from the size of the map and from the number, shape, and position of obstacles. It assumes full world knowledge but it can be easily extended in order to explore unknown environments.
																</p>
																<button onclick="show('bibtex-c11')">bibtex</button>
																<button onclick="show('abstract-c11')">abstract</button>
																<button onclick="location.href='https://ieeexplore.ieee.org/document/7559130';">paper</button>
																<br><br>

																<li style="margin-bottom: 0.2cm;">E. Tosello, S. Michieletto, E. Pagello. <b>Training master students to program both
																	virtual and real autonomous robots in a teaching laboratory</b>. EDUCON 2016;
																	IEEE Global Engineering Education Conference; Proceedings of. April 10-13, 2016. Abu
																	Dhabi (AUE).</li>
																	<pre id="hidden-div-bibtex-c12" style="display: none">
@INPROCEEDINGS{7474615,
author={Tosello, Elisa and Michieletto, Stefano and Pagello, Enrico},
booktitle={2016 IEEE Global Engineering Education Conference (EDUCON)},
title={Training master students to program both virtual and real autonomous robots in a teaching laboratory},
year={2016},
volume={},
number={},
pages={621-630},
doi={10.1109/EDUCON.2016.7474615}}
																	</pre>
																	<p id="hidden-div-abstract-c12" class="well" style="display: none">
The paper describes how the graduate course "Autonomous Robotics" innovatively introduces robotics to Master of Science students of the Faculty of Computer Engineering of the University of Padova (Italy). The main contributions are: 1) The adoption of a Project-Based Learning constructivist approach. This teaching methodology makes students able to autonomously build their robotic knowledge base; 2) The assignment of laboratory experiences according to an increasing difficulty, from mobile robots (the simple Lego Mindstorms NXT) to humanoids (the Vstone Robovie-X and the Aldebaran NAO). Humanoids are not a widespread teaching tool because of their complexity: the course simplifies the resolution of the robots stability problem by adopting teleoperation; 3) The adoption of the open-source Robot Operating System framework. The framework encourages students to implement reusable code. The effectiveness of the adopted approach has been proven building a team of students that had successfully concluded the course. The team is participating in the European Robotics Challenges and has successfully accomplished the challenge's first stage.
																	</p>
																	<button onclick="show('bibtex-c12')">bibtex</button>
																	<button onclick="show('abstract-c12')">abstract</button>
																	<button onclick="location.href='https://doi.org/10.1109/EDUCON.2016.7474615';">paper</button>
																	<br><br>

																	<li style="margin-bottom: 0.2cm;">S. Michieletto, E. Tosello, F. Romanelli, V. Ferrara, and E. Menegatti. <b><a href="">ROS-I Interface
																		for COMAU Robots</a></b>. Simulation, Modeling, and Programming for Autonomous Robots.
																		4th International Conference, SIMPAR 2014; Proceedings of. October 20-23, 2014. Bergamo
																		(Italy). Online ISBN: 978-3-319-11900-7. pp. 243-254.</li>
																		<pre id="hidden-div-bibtex-c13" style="display: none">
@InProceedings{10.1007/978-3-319-11900-7_21,
author="Michieletto, Stefano and Tosello, Elisa and Romanelli, Fabrizio and Ferrara, Valentina and Menegatti, Emanuele",
editor="Brugali, Davide and Broenink, Jan F. and Kroeger, Torsten and MacDonald, Bruce A.",
title="ROS-I Interface for COMAU Robots",
booktitle="Simulation, Modeling, and Programming for Autonomous Robots",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="243--254",
isbn="978-3-319-11900-7"}</pre>
																		<p id="hidden-div-abstract-c13" class="well" style="display: none">
The following paper presents the ROS-I interface developed to control Comau manipulators. Initially, the Comau controller allowed users to command a real robot thanks to motion primitives formulated through a Comau motion planning library. Now, either a ROS or a non ROS -compliant platform can move either a real or a virtual Comau robot using any motion planning library. Comau modules have been wrapped within ROS and a virtual model of a Comau robot has been created. The manufacturer controller has been innovatively used to drive both the real and the simulated automata.
																		</p>
																		<button onclick="show('bibtex-c13')">bibtex</button>
																		<button onclick="show('abstract-c13')">abstract</button>
																		<button onclick="location.href='https://doi.org/10.1007/978-3-319-11900-7_21';">paper</button>
																		<br><br>
																		<li style="margin-bottom: 0.2cm;">N. Boscolo, E. Tosello, S. Tonello, M. Finotto, R. Bortoletto, and E. Menegatti. <b>
																			A Constraint Based Motion Optimization System for Quality Inspection Process
																			Improvement</b>. Simulation, Modeling, and Programming for Autonomous Robots. 4th
																			International Conference, SIMPAR 2014; Proceedings of. October 20-23, 2014. Bergamo
																			(Italy). Online ISBN: 978-3-319-11900-7. pp. 545-553.</li>
																			<pre id="hidden-div-bibtex-c14" style="display: none">
@InProceedings{10.1007/978-3-319-11900-7_46,
author="Boscolo, Nicol{\`o} and Tosello, Elisa and Tonello, Stefano and Finotto, Matteo and Bortoletto, Roberto and Menegatti, Emanuele",
editor="Brugali, Davide and Broenink, Jan F. and Kroeger, Torsten and MacDonald, Bruce A.",
title="A Constraint Based Motion Optimization System for Quality Inspection Process Improvement",
booktitle="Simulation, Modeling, and Programming for Autonomous Robots",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="545--553",
isbn="978-3-319-11900-7"}</pre>
																			<p id="hidden-div-abstract-c14"class="well" style="display: none">
This paper presents a motion optimization system for an industrial quality inspection process where a vision device coupled with a manipulator robot arm is able to perform quality and completeness inspection on a complex solid part. In order to be deployed in an industrial production plant, the proposed system has been engineered and integrated as a module of an offline simulator, called WorkCellSimulator, conceived to simulate robot tasks in industrial environments. The novelty of the paper concerns the introduction of time constraints into the motion planning algorithms. Then, these algorithms have been deeply integrated with artificial intelligence techniques in order to optimize the inspection cycle time. This integration makes the application suitable for time-constrained processes like, e.g., autonomous industrial painting or autonomous thermo-graphic detection of cracks in metallic and composite materials.
																			</p>
																			<button onclick="show('bibtex-c14')">bibtex</button>
																			<button onclick="show('abstract-c14')">abstract</button>
																			<button onclick="location.href='https://doi.org/10.1007/978-3-319-11900-7_46';">paper</button>
																			<br><br>
																			<li style="margin-bottom: 0.2cm;">E. Tosello, S. Michieletto, A. Bisson, E. Pagello, and E. Menegatti. <b>A Learning from
																				Demonstration Framework for Manipulation Tasks</b>. ISR/Robotik 2014; 45th Inter-
																				national Symposium on Robotics; Proceedings of. June 2-3, 2014. Munich (Germany).
																				ISBN: 978-3-8007-3601-0. pp. 1-7.</li>
																				<pre id="hidden-div-bibtex-c15" style="display: none">
@INPROCEEDINGS{6840117,
author={Tosello, Elisa and Michieletto, Stefano and Bisson, Andrea and Pagello, Enrico and Menegatti, Emanuele},
booktitle={ISR/Robotik 2014; 41st International Symposium on Robotics},
title={A Learning from Demonstration Framework for Manipulation Tasks},
year={2014},
volume={},
number={},
pages={1-7},
doi={}}</pre>
																				<p id="hidden-div-abstract-c15" class="well" style="display: none">
This paper presents a Robot Learning from Demonstration (RLfD) framework for teaching manipulation tasks in an industrial environment: the system is able to learn a task performed by a human demonstrator and reproduce it through a manipulator robot. An RGB-D sensor acquires the scene (human in action); a skeleton tracking algorithm extracts the useful information from the images acquired (positions and orientations of skeleton joints); and this information is given as input to the motion re-targeting system that remaps the skeleton joints into the manipulator ones. After the remapping, a model for the robot motion controller is retrieved by applying first a Gaussian Mixture Model (GMM) and then a Gaussian Mixture Regression (GMR) on the collected data. Two types of controller are modeled: a position controller and a velocity one. The former was presented in [10] inclusive of simulation tests, and here it has been upgraded extended the proves to a real robot. The latter is proposed for the first time in this work and tested both in simulation and with the real robot. Experiments were performed using a Comau Smart5 SiX manipulator robot and let to show a comparison between the two controllers starting from natural human demonstrations.
																				</p>
																				<button onclick="show('bibtex-c15')">bibtex</button>
																				<button onclick="show('abstract-c15')">abstract</button>
																				<button onclick="location.href='https://ieeexplore.ieee.org/abstract/document/6840117';">paper</button>
																				<br><br>

																				<li style="margin-bottom: 0.2cm;">D. Kurabayashi, Y.Takahashi, R. Minegishi, E. Tosello, E. Pagello, R. Kanzaki. <b>Property
																					Investigation of Chemical Plume Tracing Algorithm in an Insect Using Bio-
																					machine Hybrid System</b>. Living Machines. 29 July - 2 August, 2013. London (United
																					Kindom). pp. 131-142.</li>
																					<pre id="hidden-div-bibtex-c16" style="display: none">
@InProceedings{10.1007/978-3-642-39802-5_12,
author="Kurabayashi, Daisuke and Takahashi, Yosuke and Minegishi, Ryo and Tosello, Elisa and Pagello, Enrico and Kanzaki, Ryohei",
editor="Lepora, Nathan F. and Mura, Anna and Krapp, Holger G. and Verschure, Paul F. M. J. and Prescott, Tony J.",
title="Property Investigation of Chemical Plume Tracing Algorithm in an Insect Using Bio-machine Hybrid System",
booktitle="Biomimetic and Biohybrid Systems",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="131--142",
isbn="978-3-642-39802-5"}</pre>
																					<p id="hidden-div-abstract-c16" class="well" style="display: none">
In this study, we investigated an aspect of the chemical plume tracing behavior of an insect by using a bio-machine hybrid system. We implemented an experimental system by which an insect brain was connected to a robot body. We observed th neural responses to external disturbances and transitions at changes in the motor gain of the robot body. Based on the results of the experiments, we identified a simple control model for the angular velocity of the behavior. We subsequently investigated the effect of the rotational velocity by using information entropy in computer simulations.
																					</p>
																					<button onclick="show('bibtex-c16')">bibtex</button>
																					<button onclick="show('abstract-c16')">abstract</button>
																					<button onclick="location.href='https://doi.org/10.1007/978-3-642-39802-5_12';">paper</button>
																					<br><br>

																					<li style="margin-bottom: 0.2cm;">S. Tonello, G. P. Zanetti, M. Finotto, R. Bortoletto, E. Tosello, E. Menegatti. <b>WorkCell-
																						Simulator: A 3D Simulator for Intelligent Manufacturing</b>. Simulation, Model-
																						ing, and Programming for Autonomous Robots. Springer Verlag Berlin. November
																						5-8, 2012. Tsukuba (Japan). pp. 311-322.</li>
																						<pre id="hidden-div-bibtex-c17" style="display: none">
@InProceedings{10.1007/978-3-642-34327-8_29,
author="Tonello, Stefano and Zanetti, Guido Piero and Finotto, Matteo and Bortoletto, Roberto and Tosello, Elisa and Menegatti, Emanuele",
editor="Noda, Itsuki and Ando, Noriaki and Brugali, Davide and Kuffner, James J.",
title="WorkCellSimulator: A 3D Simulator for Intelligent Manufacturing",
booktitle="Simulation, Modeling, and Programming for Autonomous Robots",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="311--322",
isbn="978-3-642-34327-8"}</pre>
																						<p id="hidden-div-abstract-c17" class="well" style="display: none">
This paper presents WorkCellSimulator, a software platform that allows to manage an environment for the simulation of robot tasks. It uses the most advanced artificial intelligence algorithms in order to define the production process, by controlling one or more robot manipulators and machineries present in the work cell. The main goal of this software is to assist the user in defining customized production processes which involve specific automated cells. It has been developed by IT+Robotics, a spin-off company of the University of Padua, founded in 2005 from the collaboration between young researchers in the field of Robotics and a group of professors from the Department of Information Engineering, University of Padua.
																						</p>
																						<button onclick="show('bibtex-c17')">bibtex</button>
																						<button onclick="show('abstract-c17')">abstract</button>
																						<button onclick="location.href='https://doi.org/10.1007/978-3-642-34327-8_29';">Paper</button>
																						<br><br>

																					</ol>

																					<br>
																					<h1><span>WORKSHOPS</span></h1>
																					<ol style="list-style-position: inside; padding-left: 0; text-align: justify;">
																						<li style="margin-bottom: 0.2cm;">E. Tosello, E. Pagello, S. Ghidoni. <b>Combining Deep Learning and Knowledge Bases
																							to solve TAMP problems in the Cloud: benefits and challenges</b>. Collaboratively
																							Working towards Ontology-based standards for Robotics and Automation, Workshop on.
																							2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS).
																							October 5, 2018. Madrid (Spain).</li>

																							<li style="margin-bottom: 0.2cm;">F. Vendramin, E. Tosello, N. Castaman, S. Ghidoni. <b>Learning Robot Task Planning
																								primitives by means of Long Short-Term Memory Networks</b>. Combining Task
																								and Motion Planning in the frame of Cloud Robotics. Workshop of. IEEE Simpar 2018
																								International Conference. May, 16, 2018. Brisbane (Australia).</li>
																								<li style="margin-bottom: 0.2cm;">E. Tosello, Z. Fan, E. Pagello. <b>A Semantic Knwoledge Base for Cognitive Robotics
																									Manipulator</b>. Toward Intelligent Social Robots - Current Advances in Cognitive Robotics,
																									Workshop on. Seul, Korea. Nov 3rd, 2015.</li>
																									<li style="margin-bottom: 0.2cm;">Z. Fan, E. Tosello, M. Palmia, and E. Pagello. <b>Applying Semantic Web Technologies
																										to Multi-Robot Coordination</b>. NRF-IAS-2014; New Research Frontiers for Intelligent
																										Autonomous Systems; Workshop. July 19, 2014. Venice (Italy).</li>
																										<li style="margin-bottom: 0.2cm;">E. Tosello, R. Bortoletto, S. Michieletto, E. Pagello, and E. Menegatti. <b>An Integrated
																											System to approach the Programming of Humanoid Robotics</b>. 4th International
																											Workshop Teaching Robotics, Teaching with Robotics & 5th International Conference
																											Robotics in Education; Proceedings of. July 18, 2014. Padova (Italy). ISBN 978-88-95872-
																											06-3. pp. 93-100.</li>
																										</ol>
																									</div>

																								</div>

																							</div>
																						</div>
																					</section>
																					<!-- end publications -->

																					<script>
																					function show(par) {
																						var x = document.getElementById("hidden-div-"+par);
																						if (x.style.display === "none") {
																							x.style.display = "block";
																						} else {
																							x.style.display = "none";
																						}
																					}
																					</script>

																				</body>
																				</html>
